{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to train a DistilRoBERTa-based classifier to test the outputs of the translation models. The classifier labels each translation as either Shakespearean or Modern English and checks whether the output matches the intended style of the translator model.\n",
        "\n"
      ],
      "metadata": {
        "id": "_F2i-lMU09Gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install (and update if already installed) the transformers library from HuggingFace, which gives us the ability to load the pretrained model, tokenize text, and train."
      ],
      "metadata": {
        "id": "g3V4L31I2mp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "xGoCKH87PG7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We upload the file shakespeare_modern.tsv, which we will train the classifier on. It holds a column for Shakespearean English and a column for respective Modern English translations."
      ],
      "metadata": {
        "id": "hw4j2h3B2-8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "LVEVpVUMPG3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the tsv into a dataframe, which also labels one of the columns as \"shakespeare\" and the other as \"modern\"."
      ],
      "metadata": {
        "id": "VsqAOhOS3g2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"shakespeare_modern.tsv\", sep=\"\\t\", header=None, names=[\"shakespeare\", \"modern\"])"
      ],
      "metadata": {
        "id": "HoKygbnTPGvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Shakespeare dataset is created and labeled as 1 and a Modern dataset is created and labeled as 0. They are combined so that there is categorization on what is Shakespearean and what is Modern."
      ],
      "metadata": {
        "id": "4ooUIlc_3uD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shakes = pd.DataFrame({\n",
        "    \"text\": df[\"shakespeare\"],\n",
        "    \"label\": 1\n",
        "})\n",
        "\n",
        "modern = pd.DataFrame({\n",
        "    \"text\": df[\"modern\"],\n",
        "    \"label\": 0\n",
        "})\n",
        "\n",
        "full_df = pd.concat([shakes, modern], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "0kInf569PQMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This splits the dataset so that 80% is used for training and 20% is used for testing."
      ],
      "metadata": {
        "id": "VqYc-ZNF4vIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    full_df[\"text\"],\n",
        "    full_df[\"label\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "dZo-BDsLPQBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensures that the data is cleaned so that there are no missing values and are in the format of strings."
      ],
      "metadata": {
        "id": "Bi0HuWUI49td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_clean = X_train.fillna(\"\").astype(str).tolist()\n",
        "X_test_clean  = X_test.fillna(\"\").astype(str).tolist()\n",
        "y_train_clean = y_train.tolist()\n",
        "y_test_clean  = y_test.tolist()"
      ],
      "metadata": {
        "id": "TkC_OWJNQujq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This imports the tokenizer and the pre-trained model, distilroberta-base."
      ],
      "metadata": {
        "id": "OeYvgRNT5LJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "cFdlzsSLQRZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are functions where `init` tokenizes the text of the passed in dataset, stores their labels (0 for modern English, 1 for Shakespearean English), and sets padding for the encodings. `len` returns the length of the dataset and `getItem` retrieves the ith item from the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "artH4q2J5iI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "VrVj5_v-P7pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates the training dataset and test dataset by using `TextDataSet` to tokenize the texts."
      ],
      "metadata": {
        "id": "xuOSM7dM6YJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(X_train_clean, y_train_clean, tokenizer)\n",
        "test_dataset  = TextDataset(X_test_clean, y_test_clean, tokenizer)\n"
      ],
      "metadata": {
        "id": "vu9INN0yQ0t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sets the hyperparameters for the training loop. We set the training to 2 epochs and evaluated validation loss and training loss based on each epoch."
      ],
      "metadata": {
        "id": "w27yNNhl6rdJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RCC1RLwO8TA"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trains the model and outputs evaluation metrics at the end such as validation loss."
      ],
      "metadata": {
        "id": "X6ydgRyh61Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", results)"
      ],
      "metadata": {
        "id": "l3u8vbpLPCM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This outputs metrics based on the training dataset to get training loss."
      ],
      "metadata": {
        "id": "FWB6H7JH66LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = trainer.evaluate(train_dataset)\n",
        "print(\"Training metrics:\", train_metrics)"
      ],
      "metadata": {
        "id": "RqrUtmrUfC5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plots training loss vs. validation loss to determine when overfitting happened."
      ],
      "metadata": {
        "id": "T_E5xq776-qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "\n",
        "train_loss = [x[\"loss\"] for x in logs if \"loss\" in x]\n",
        "eval_loss  = [x[\"eval_loss\"] for x in logs if \"eval_loss\" in x]\n",
        "epochs     = [x[\"epoch\"] for x in logs if \"eval_loss\" in x]\n",
        "\n",
        "plt.plot(epochs, eval_loss, label=\"Validation Loss\")\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ak12Si25lHoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a function that takes in a sentence and uses the classifer to categorize it as either \"Shakespeare\" or \"Modern\"."
      ],
      "metadata": {
        "id": "MmlXkuyU7C-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    pred_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return \"Shakespeare\" if pred_class == 1 else \"Modern\""
      ],
      "metadata": {
        "id": "cvh5HgE0UoYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some tests seeing how the classifer would categorize sample sentences. It was mostly accurate."
      ],
      "metadata": {
        "id": "SAzGoxaa7Kbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_sentence(\"He walks among shadows, carrying memories not his own.\"))\n",
        "print(classify_sentence(\"The morning sun whispers secrets the night forgot\"))\n",
        "print(classify_sentence(\"The wind bends the trees as if sharing some quiet counsel.\"))\n",
        "print(classify_sentence(\"She lingers by the window, pondering what tomorrow might bring.\"))\n",
        "print(classify_sentence(\"Methinks the night doth hide more than the eye can see.\"))\n",
        "print(classify_sentence(\"I shall attend the meeting tomorrow, though I might be late.\"))\n",
        "print(classify_sentence(\"The river murmurs softly, carrying tales no one recalls.\"))"
      ],
      "metadata": {
        "id": "ycUfDIoQUvPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to compare training accuracy and test accuracy to ensure that it has good accuracy, but that they aren't too far apart so that we know it generalizes well."
      ],
      "metadata": {
        "id": "IOiOu6ha7QrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "train_preds_output = trainer.predict(train_dataset)\n",
        "train_preds = np.argmax(train_preds_output.predictions, axis=1)\n",
        "print(\"Train accuracy:\", accuracy_score(y_train, train_preds))\n",
        "\n",
        "test_preds_output = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_preds_output.predictions, axis=1)\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, test_preds))"
      ],
      "metadata": {
        "id": "OA9DADezUzvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next two cells are for uploading our data:\n",
        "\n",
        "\n",
        "*  `modern_test.tsv` that has one column of original Modern English from our test set and a second column of translated Early Modern English to Modern English that was generated by one of our models\n",
        "*   `shakespeare_test.tsv` that has one column of original Early Modern English from our test set and a second column of translated Modern English to Early Modern English that was generated by one of our models\n"
      ],
      "metadata": {
        "id": "D_o8DR719iMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload modern_test.tsv and shakespeare_test.tsv\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "hkLi-KcnU2K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload modern_test.tsv and shakespeare_test.tsv\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "uMeF94xszdyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then prepare the data into `DatasetDict` objects with two colummns."
      ],
      "metadata": {
        "id": "LcflP1d09wCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "\n",
        "modern_testset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"full\": str(Path(\"modern_test.tsv\"))},\n",
        "    delimiter=\"\\t\",\n",
        "    column_names=[\"original_modern\", \"translated_from_earlymodern\"]\n",
        ")\n",
        "\n",
        "shakes_testset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"full\": str(Path(\"shakespeare_test.tsv\"))},\n",
        "    delimiter=\"\\t\",\n",
        "    column_names=[\"original_earlymodern\", \"translated_from_modern\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "fSuLq2Rczem7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foes through the modern data and ensures it skips empty entries and that the entries are a string. It then makes a prediction by using the future defined function, `classify_sentence`."
      ],
      "metadata": {
        "id": "Q3xJZo0f93Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in modern_testset[\"full\"]:\n",
        "    translated = row[\"translated_from_earlymodern\"]\n",
        "\n",
        "    if translated is None:\n",
        "        continue\n",
        "\n",
        "    translated = str(translated)\n",
        "    pred = classify_sentence(translated)\n"
      ],
      "metadata": {
        "id": "TzB7RuGQLjaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function, `classify_sentence` that takes an input sentence and uses the classifier to categorize it as Modern (0) or Shakespeare (1)."
      ],
      "metadata": {
        "id": "Cgmsrdp7-w4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    if sentence is None or sentence == \"\":\n",
        "        return None  # or a default class\n",
        "\n",
        "    inputs = tokenizer(text=str(sentence), return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    pred_class = torch.argmax(logits, dim=1).item()\n",
        "    return pred_class  # 0=Modern, 1=Shakespeare\n"
      ],
      "metadata": {
        "id": "S8vtJ55Ozig0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These keep track of what predictions by the model were correct by looping through the dataset, reading the tranlater model's output, and seeing if it matches the classifier's output. It repeats this for both translating from Modern English to Shakespearean English and from Shakespearean English to Modern English."
      ],
      "metadata": {
        "id": "mkXOYMXW-9D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for row in modern_testset[\"full\"]:\n",
        "    translated = row[\"translated_from_earlymodern\"]\n",
        "    pred = classify_sentence(translated)\n",
        "\n",
        "    if pred == 0:  # expected: Modern\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(\"Modern Test Accuracy:\", correct / total)"
      ],
      "metadata": {
        "id": "C3tX6jdfzsmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for row in shakes_testset[\"full\"]:\n",
        "    translated = row[\"translated_from_modern\"]\n",
        "    pred = classify_sentence(translated)\n",
        "\n",
        "    if pred == 1:  # expected: Shakespeare\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(\"Shakespeare Test Accuracy:\", correct / total)"
      ],
      "metadata": {
        "id": "EjxDNViazwgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}