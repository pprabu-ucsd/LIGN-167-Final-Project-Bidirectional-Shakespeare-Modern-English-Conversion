{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to calculate the Word Error Rate (WER) between model outputs and the test set. As in HW 2, this is computed as (S+D+I)/N where S is the number of times the system substitutes one source word for a different word in its transcript, D is the number of times the system deletes a source word, I is the number of times the system inserts a word in the transcript where there is no corresponding source word, and N is the total number of words in the source."
      ],
      "metadata": {
        "id": "e4sU2tT92T3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the necessary libraries and modules to be able to process input files."
      ],
      "metadata": {
        "id": "q-7Gh3ha193f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "cBEJ1Whd2Ppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `wer` function calculates the WER between a source transcription and the output generated by one of our models. It does this using dynamic programming and outputs the WER, the number of substitutions (S), the number of deletions (D), and the number of insertions (I)."
      ],
      "metadata": {
        "id": "ocfQpX0n4LCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn1PzRiajKmB"
      },
      "outputs": [],
      "source": [
        "def wer(source, ours):\n",
        "\n",
        "    # Tokenize\n",
        "    r = source.split()\n",
        "    h = ours.split()\n",
        "    len_r = len(r)\n",
        "    len_h = len(h)\n",
        "\n",
        "    # DP matrix: rows = source, cols = model output (ours)\n",
        "    dp = [[0] * (len_h + 1) for _ in range(len_r + 1)]\n",
        "\n",
        "    # Operation matrix to help backtrack edits\n",
        "    backtrace = [[None] * (len_h + 1) for _ in range(len_r + 1)]\n",
        "\n",
        "    # Initialize boundaries\n",
        "    for i in range(1, len_r + 1):\n",
        "        dp[i][0] = i\n",
        "        backtrace[i][0] = \"D\"\n",
        "\n",
        "    for j in range(1, len_h + 1):\n",
        "        dp[0][j] = j\n",
        "        backtrace[0][j] = \"I\"\n",
        "\n",
        "    # Fill DP table\n",
        "    for i in range(1, len_r + 1):\n",
        "        for j in range(1, len_h + 1):\n",
        "            if r[i - 1] == h[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "                backtrace[i][j] = \"OK\"\n",
        "            else:\n",
        "                sub = dp[i - 1][j - 1] + 1\n",
        "                ins = dp[i][j - 1] + 1\n",
        "                dele = dp[i - 1][j] + 1\n",
        "\n",
        "                dp[i][j] = min(sub, ins, dele)\n",
        "\n",
        "                if dp[i][j] == sub:\n",
        "                    backtrace[i][j] = \"S\"\n",
        "                elif dp[i][j] == ins:\n",
        "                    backtrace[i][j] = \"I\"\n",
        "                else:\n",
        "                    backtrace[i][j] = \"D\"\n",
        "\n",
        "    # Backtrack to count S, D, I\n",
        "    i, j = len_r, len_h\n",
        "    S = D = I = 0\n",
        "\n",
        "    while i > 0 or j > 0:\n",
        "        op = backtrace[i][j]\n",
        "\n",
        "        if op == \"OK\":\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif op == \"S\":\n",
        "            S += 1\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif op == \"D\":\n",
        "            D += 1\n",
        "            i -= 1\n",
        "        elif op == \"I\":\n",
        "            I += 1\n",
        "            j -= 1\n",
        "\n",
        "    wer_value = (S + D + I) / len_r if len_r > 0 else float(\"inf\")\n",
        "    return wer_value, S, D, I\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next two cells are for uploading our data:\n",
        "\n",
        "\n",
        "*  `modern_test.tsv` that has one column of original Modern English from our test set and a second column of translated Early Modern English to Modern English that was generated by one of our models\n",
        "*   `shakespeare_test.tsv` that has one column of original Early Modern English from our test set and a second column of translated Modern English to Early Modern English that was generated by one of our models\n",
        "\n"
      ],
      "metadata": {
        "id": "rr8UO6kY1-vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# file modern_test.tsv"
      ],
      "metadata": {
        "id": "IN4V50XjqMXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# file shakespeare_test.tsv"
      ],
      "metadata": {
        "id": "GaM2xVnt21ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then prepare the data into `DatasetDict` objects with two colummns."
      ],
      "metadata": {
        "id": "wjTlmicp2HI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shakes_testset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"full\": str(Path(\"./shakespeare_test.tsv\"))},\n",
        "    delimiter=\"\\t\",\n",
        "    column_names=[\"original\", \"translated\"]\n",
        " )\n",
        "\n",
        "modern_testset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"full\": str(Path(\"./modern_test.tsv\"))},\n",
        "    delimiter=\"\\t\",\n",
        "    column_names=[\"original\", \"translated\"]\n",
        ")"
      ],
      "metadata": {
        "id": "ElFvzzfDI14i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculates the overall WER, S, D, and I from the entire test set by applying the `wer` function for each pair of data in the test set given."
      ],
      "metadata": {
        "id": "CK283ogP2H-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def error_calc(testset):\n",
        "  error = 0\n",
        "  subs = 0\n",
        "  dels = 0\n",
        "  ins = 0\n",
        "  for row in testset[\"full\"]:\n",
        "          original = str(row[\"original\"])\n",
        "          translated = str(row[\"translated\"])\n",
        "          w, S, D, I = wer(original, translated)\n",
        "          subs += S\n",
        "          dels += D\n",
        "          ins  += I\n",
        "          error += w\n",
        "  average_wer = error / len(testset[\"full\"])\n",
        "  return average_wer, subs, dels, ins"
      ],
      "metadata": {
        "id": "TX_-SqkxkuaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the next two cells apply the WER calculations to the two types of translation (Modern English to Early Modern English and Early Modern English to Modern English)."
      ],
      "metadata": {
        "id": "IVJUvxIc2IlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w, S, D, I = error_calc(shakes_testset)\n",
        "\n",
        "print(\"WER:\", w)\n",
        "print(\"Substitutions:\", S)\n",
        "print(\"Deletions:\", D)\n",
        "print(\"Insertions:\", I)"
      ],
      "metadata": {
        "id": "BxlGUr1e1OCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, S, D, I = error_calc(modern_testset)\n",
        "\n",
        "print(\"WER:\", w)\n",
        "print(\"Substitutions:\", S)\n",
        "print(\"Deletions:\", D)\n",
        "print(\"Insertions:\", I)"
      ],
      "metadata": {
        "id": "XaVacR1h1iEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}